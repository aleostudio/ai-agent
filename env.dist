# App config (127.0.0.1 for localhost, 0.0.0.0 for whole network)
APP_NAME="Simple AI agent"
APP_HOST=0.0.0.0
APP_PORT=9201
API_VERSION="v1"

# Logging
DEBUG=False

# LLM config (host.docker.internal on Docker)
OLLAMA_BASE_URL="http://localhost:11434"
MODEL="llama3.2"
TEMPERATURE=0.8
